{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjSpY7t9EarL"
   },
   "source": [
    "# STINTSY Machine Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkqYEPv8ElBq"
   },
   "source": [
    "**SS1 - Group 3**\n",
    "1. BERENGUER, Beatrice A.\n",
    "2. BUENDIA, Leigh Arriane S.\n",
    "3. ENRIQUEZ, Manolo L."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmCk7kiZHPES"
   },
   "source": [
    "## **Description of the Task**\n",
    "\n",
    "With the dataset selected, the project aims to create a machine learning model that will accurately classify whether a smoke detector device should be triggered or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEV3cpmwHcIB"
   },
   "source": [
    "**<h2> List of Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TjAm42Lf-5xC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ur8mCqrHlIi"
   },
   "source": [
    "## **Description of the Dataset**\n",
    "\n",
    "The dataset selected is the **Smoke Detection Dataset** from Kaggle. The link to the dataset can be found here: https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset\n",
    "\n",
    "Collection of training data is performed with the help of IOT devices since the goal is to develop an AI based smoke detector device. Many different environments and fire sources have to be sampled to ensure a good dataset for training. A short list of different scenarios which are captured:\n",
    "\n",
    "* Normal indoor\n",
    "* Normal outdoor\n",
    "* Indoor wood fire, firefighter training area\n",
    "* Indoor gas fire, firefighter training area\n",
    "* Outdoor wood, coal, and gas grill\n",
    "* Outdoor high humidity etc.\n",
    "\n",
    "The dataset is able to capture these scenarios through the features it contains. The following is a full list of the features and their descriptions:\n",
    "\n",
    "* `UTC` - Timestamp UTC seconds\n",
    "* `Temperature` - Air Temperature\n",
    "* `Humidity` - Air Humidity\n",
    "* `TVOC` - Total Volatile Organic Compounds; measured in parts per billion\n",
    "* `eCo2` - co2 equivalent concentration; calculated from different values like TVCO\n",
    "* `Raw H2` - raw molecular hydrogen; not compensated (Bias, temperature, etc.)\n",
    "* `Raw Ethanol` - raw ethanol gas\n",
    "* `Pressure` - Air pressure\n",
    "* `PM1.0` - Particulate matter size < 1.0 µm (PM1.0). 1.0 µm < 2.5 µm (PM2.5)\n",
    "* `PM2.5` - Particulate matter size < 1.0 µm (PM1.0). 1.0 µm < 2.5 µm (PM2.5)\n",
    "* `NC0.5` - Number concentration of particulate matter. This differs from PM because NC gives the actual number of particles in the air. The raw NC is also classified by the particle size: < 0.5 µm (NC0.5); 0.5 µm < 1.0 µm (NC1.0); 1.0 µm < 2.5 µm (NC2.5);\n",
    "* `NC1.0` - Number concentration of particulate matter. This differs from PM because NC gives the actual number of particles in the air. The raw NC is also classified by the particle size: < 0.5 µm (NC0.5); 0.5 µm < 1.0 µm (NC1.0); 1.0 µm < 2.5 µm (NC2.5);\n",
    "* `NC2.5` - Number concentration of particulate matter. This differs from PM because NC gives the actual number of particles in the air. The raw NC is also classified by the particle size: < 0.5 µm (NC0.5); 0.5 µm < 1.0 µm (NC1.0); 1.0 µm < 2.5 µm (NC2.5);\n",
    "* `CNT` - Sample counter \n",
    "* `Fire Alarm` - Ground truth is \"1\" if a fire is there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us read the dataset and display the first few rows in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "MN_mVYy--z2E",
    "outputId": "e0374194-202b-4a99-9cf2-7ea5a3c305ef",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UTC</th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1654733331</td>\n",
       "      <td>20.000</td>\n",
       "      <td>57.36</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12306</td>\n",
       "      <td>18520</td>\n",
       "      <td>939.735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1654733332</td>\n",
       "      <td>20.015</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12345</td>\n",
       "      <td>18651</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1654733333</td>\n",
       "      <td>20.029</td>\n",
       "      <td>55.96</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12374</td>\n",
       "      <td>18764</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1654733334</td>\n",
       "      <td>20.044</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12390</td>\n",
       "      <td>18849</td>\n",
       "      <td>939.736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1654733335</td>\n",
       "      <td>20.059</td>\n",
       "      <td>54.69</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12403</td>\n",
       "      <td>18921</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         UTC  Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]  \\\n",
       "0           0  1654733331          20.000        57.36          0        400   \n",
       "1           1  1654733332          20.015        56.67          0        400   \n",
       "2           2  1654733333          20.029        55.96          0        400   \n",
       "3           3  1654733334          20.044        55.28          0        400   \n",
       "4           4  1654733335          20.059        54.69          0        400   \n",
       "\n",
       "   Raw H2  Raw Ethanol  Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5  CNT  \\\n",
       "0   12306        18520        939.735    0.0    0.0    0.0    0.0    0.0    0   \n",
       "1   12345        18651        939.744    0.0    0.0    0.0    0.0    0.0    1   \n",
       "2   12374        18764        939.738    0.0    0.0    0.0    0.0    0.0    2   \n",
       "3   12390        18849        939.736    0.0    0.0    0.0    0.0    0.0    3   \n",
       "4   12403        18921        939.744    0.0    0.0    0.0    0.0    0.0    4   \n",
       "\n",
       "   Fire Alarm  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('smoke_detection_iot.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how many our data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vuzcEqKvB4tZ",
    "outputId": "871f6827-1f79-4a1b-85a7-d9d9b8e29516"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62630, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of each feature in the dataset is seen below. Here we can see that all features are of data type `int64` or `float64`, categorizing this dataset to contain continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Isao9bvBDVq",
    "outputId": "e618fb83-50f5-4e89-e590-4ac28eb50103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62630 entries, 0 to 62629\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      62630 non-null  int64  \n",
      " 1   UTC             62630 non-null  int64  \n",
      " 2   Temperature[C]  62630 non-null  float64\n",
      " 3   Humidity[%]     62630 non-null  float64\n",
      " 4   TVOC[ppb]       62630 non-null  int64  \n",
      " 5   eCO2[ppm]       62630 non-null  int64  \n",
      " 6   Raw H2          62630 non-null  int64  \n",
      " 7   Raw Ethanol     62630 non-null  int64  \n",
      " 8   Pressure[hPa]   62630 non-null  float64\n",
      " 9   PM1.0           62630 non-null  float64\n",
      " 10  PM2.5           62630 non-null  float64\n",
      " 11  NC0.5           62630 non-null  float64\n",
      " 12  NC1.0           62630 non-null  float64\n",
      " 13  NC2.5           62630 non-null  float64\n",
      " 14  CNT             62630 non-null  int64  \n",
      " 15  Fire Alarm      62630 non-null  int64  \n",
      "dtypes: float64(8), int64(8)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per feature, the number of unique values are found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrIZ3cvVBshP",
    "outputId": "86fdba8c-3a97-4e0d-f849-a35fddcfb3ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        62630\n",
       "UTC               62630\n",
       "Temperature[C]    21672\n",
       "Humidity[%]        3890\n",
       "TVOC[ppb]          1966\n",
       "eCO2[ppm]          1713\n",
       "Raw H2             1830\n",
       "Raw Ethanol        2659\n",
       "Pressure[hPa]      2213\n",
       "PM1.0              1337\n",
       "PM2.5              1351\n",
       "NC0.5              3093\n",
       "NC1.0              4113\n",
       "NC2.5              1161\n",
       "CNT               24994\n",
       "Fire Alarm            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ediHCEeCKWuJ"
   },
   "source": [
    "**<h2> Data Preprocessing and Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers data cleaning and preprocessing techniques that are essential to perform before using the dataset for model training. First, let us clean the data to be able to process it properly and efficiently later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start the data cleaning process by checking for any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SW_UbTTHCSlr",
    "outputId": "466cf3d4-46e0-4ff4-83c4-bdfb84d6ca8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "UTC               0\n",
       "Temperature[C]    0\n",
       "Humidity[%]       0\n",
       "TVOC[ppb]         0\n",
       "eCO2[ppm]         0\n",
       "Raw H2            0\n",
       "Raw Ethanol       0\n",
       "Pressure[hPa]     0\n",
       "PM1.0             0\n",
       "PM2.5             0\n",
       "NC0.5             0\n",
       "NC1.0             0\n",
       "NC2.5             0\n",
       "CNT               0\n",
       "Fire Alarm        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, there are no null values in the dataset. Let us now check for any duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnHyjdRhIQGj",
    "outputId": "724f7601-5347-4075-d2c4-07721f37476a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "62625    False\n",
       "62626    False\n",
       "62627    False\n",
       "62628    False\n",
       "62629    False\n",
       "Length: 62630, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62630"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.duplicated()=='False').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have checked for null and duplicate values, we can remove any unnecessary columns in the dataset that we will not use for model training. We can drop the `Unnamed: 0` and `UTC` features because these will be irrelevant for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "p9u1FXuBGXmU",
    "outputId": "bcdb6727-2456-4790-868c-38e752c7a360"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.000</td>\n",
       "      <td>57.36</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12306</td>\n",
       "      <td>18520</td>\n",
       "      <td>939.735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.015</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12345</td>\n",
       "      <td>18651</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.029</td>\n",
       "      <td>55.96</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12374</td>\n",
       "      <td>18764</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.044</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12390</td>\n",
       "      <td>18849</td>\n",
       "      <td>939.736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.059</td>\n",
       "      <td>54.69</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12403</td>\n",
       "      <td>18921</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]  Raw H2  Raw Ethanol  \\\n",
       "0          20.000        57.36          0        400   12306        18520   \n",
       "1          20.015        56.67          0        400   12345        18651   \n",
       "2          20.029        55.96          0        400   12374        18764   \n",
       "3          20.044        55.28          0        400   12390        18849   \n",
       "4          20.059        54.69          0        400   12403        18921   \n",
       "\n",
       "   Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5  CNT  Fire Alarm  \n",
       "0        939.735    0.0    0.0    0.0    0.0    0.0    0           0  \n",
       "1        939.744    0.0    0.0    0.0    0.0    0.0    1           0  \n",
       "2        939.738    0.0    0.0    0.0    0.0    0.0    2           0  \n",
       "3        939.736    0.0    0.0    0.0    0.0    0.0    3           0  \n",
       "4        939.744    0.0    0.0    0.0    0.0    0.0    4           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['Unnamed: 0', 'UTC'], axis = 1, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assign our `X` and `y` values. `X` will contain the data from all the columns except the `Fire Alarm` column. On the other hand, `y` will contain the data from the `Fire Alarm` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "62nCv6KLHoro",
    "outputId": "914c5b42-3c1d-4357-a8f7-ae573def7b3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.000</td>\n",
       "      <td>57.36</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12306</td>\n",
       "      <td>18520</td>\n",
       "      <td>939.735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.015</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12345</td>\n",
       "      <td>18651</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.029</td>\n",
       "      <td>55.96</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12374</td>\n",
       "      <td>18764</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.044</td>\n",
       "      <td>55.28</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12390</td>\n",
       "      <td>18849</td>\n",
       "      <td>939.736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.059</td>\n",
       "      <td>54.69</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12403</td>\n",
       "      <td>18921</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]  Raw H2  Raw Ethanol  \\\n",
       "0          20.000        57.36          0        400   12306        18520   \n",
       "1          20.015        56.67          0        400   12345        18651   \n",
       "2          20.029        55.96          0        400   12374        18764   \n",
       "3          20.044        55.28          0        400   12390        18849   \n",
       "4          20.059        54.69          0        400   12403        18921   \n",
       "\n",
       "   Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5  CNT  \n",
       "0        939.735    0.0    0.0    0.0    0.0    0.0    0  \n",
       "1        939.744    0.0    0.0    0.0    0.0    0.0    1  \n",
       "2        939.738    0.0    0.0    0.0    0.0    0.0    2  \n",
       "3        939.736    0.0    0.0    0.0    0.0    0.0    3  \n",
       "4        939.744    0.0    0.0    0.0    0.0    0.0    4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['Fire Alarm'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YX5N9UNGH46R",
    "outputId": "100d0698-063b-4659-c05e-cffddbd61807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Fire Alarm, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Fire Alarm']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've assigned our data `X` and `y`, we are almost ready for model training. We can observe that our data values in different columns are very far apart from each other. `Raw H2` and `Raw Ethanol` have values of 12,000 and 18,000 above, while other columns would have very small numbers that are close to 0.\n",
    "\n",
    "To address this, we scale the data's range of values to fit within 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SfTaQEXKGOrL"
   },
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "pjDW274HGSDr",
    "outputId": "8167af47-02f6-436b-b219-43d88bedf2d6",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512692</td>\n",
       "      <td>0.723239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522488</td>\n",
       "      <td>0.525685</td>\n",
       "      <td>0.986014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512875</td>\n",
       "      <td>0.712535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534928</td>\n",
       "      <td>0.547185</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.513046</td>\n",
       "      <td>0.701520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544179</td>\n",
       "      <td>0.565731</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.513229</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549282</td>\n",
       "      <td>0.579682</td>\n",
       "      <td>0.986125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.513412</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553429</td>\n",
       "      <td>0.591498</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]    Raw H2  Raw Ethanol  \\\n",
       "0        0.512692     0.723239        0.0        0.0  0.522488     0.525685   \n",
       "1        0.512875     0.712535        0.0        0.0  0.534928     0.547185   \n",
       "2        0.513046     0.701520        0.0        0.0  0.544179     0.565731   \n",
       "3        0.513229     0.690971        0.0        0.0  0.549282     0.579682   \n",
       "4        0.513412     0.681818        0.0        0.0  0.553429     0.591498   \n",
       "\n",
       "   Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5      CNT  \n",
       "0       0.986014    0.0    0.0    0.0    0.0    0.0  0.00000  \n",
       "1       0.987013    0.0    0.0    0.0    0.0    0.0  0.00004  \n",
       "2       0.986347    0.0    0.0    0.0    0.0    0.0  0.00008  \n",
       "3       0.986125    0.0    0.0    0.0    0.0    0.0  0.00012  \n",
       "4       0.987013    0.0    0.0    0.0    0.0    0.0  0.00016  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(scale.fit_transform(X),columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normalized data, we can now split our data to have a train and test set. This will be split to `80%` going to the train set and `20%` going to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KcFk4-JMCPMZ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, before the train and test set can be used, let us check if our target classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lILZQQ76IVdf",
    "outputId": "3c8e2c7d-14ca-4928-81cb-b2c13761e999"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35836\n",
       "0    14268\n",
       "Name: Fire Alarm, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the target classes are imbalanced with class `1` having `blank` values, while `0` has `blank`. We can address this through over-sampling the minority class using the **Synthetic Minority Over-sampling Technique**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2Vj_z1vcIaat"
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFR7L4HVIskk",
    "outputId": "aec6b4de-f6b4-4794-cc41-9f9a56c23c97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35836\n",
       "1    35836\n",
       "Name: Fire Alarm, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the values of each target class are balanced. Our train and test sets are now ready to be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsE9fMfQKlrf"
   },
   "source": [
    "**<h2> Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Visualization Tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using 15% of our data for testing and 85% of our data for training. The figure below shows a pie chart of how much will be used for training and testing. The values in the pie chart are 82.6% for training and 17.4% for testing, this is because we used `SMOTE (Synthetic Minority Oversampling Technique)` to balance the training dataset which affects the percentage of the data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71672, 12526]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.pie([X_train.shape[0],X_test.shape[0]], labels=[\"Training Set\", \"Test Set\"], autopct='%1.1f%%')\n",
    "ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n",
    "ax.set_title('Data Split')\n",
    "print([X_train.shape[0],X_test.shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During data pre-processing and cleaning, we used `SMOTE (Synthetic Minority Oversampling Technique)` in the training dataset which creates a balance in the dataset. The chart below shows that the labels are 50/50 which means that the training dataset has the same amount of number per class. Therefore, models are now easier to train since this prevents becoming biased towards one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Set Labels')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.pie([y_train.value_counts()[0],y_train.value_counts()[1]], labels=[\"Label 0\", \"Label 1\"], autopct='%1.1f%%')\n",
    "ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n",
    "ax.set_title('Training Set Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart below shows that there are more `Label 0` than `Label 1`. This is because we do not need to balance it since we are already dealing with the test data which should be authentic in order to test if our model really is accurate. The chart below shows the data of how many rows there are per class which are 28.8% for `0` (No fire detected) and 71.2% for `1` (Fire detected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test Set Labels')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.pie([y_test.value_counts()[0],y_test.value_counts()[1]], labels=[\"Label 0\", \"Label 1\"], autopct='%1.1f%%')\n",
    "ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n",
    "ax.set_title('Test Set Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the basic statistic for our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>71672.000000</td>\n",
       "      <td>7.167200e+04</td>\n",
       "      <td>71672.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.476804</td>\n",
       "      <td>0.560188</td>\n",
       "      <td>0.044760</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.721350</td>\n",
       "      <td>0.744930</td>\n",
       "      <td>0.845509</td>\n",
       "      <td>0.010480</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>3.753135e-03</td>\n",
       "      <td>0.323073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.178753</td>\n",
       "      <td>0.158868</td>\n",
       "      <td>0.169140</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>0.105182</td>\n",
       "      <td>0.122311</td>\n",
       "      <td>0.147471</td>\n",
       "      <td>0.077818</td>\n",
       "      <td>0.050823</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>0.049729</td>\n",
       "      <td>4.114791e-02</td>\n",
       "      <td>0.296541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.416385</td>\n",
       "      <td>0.543423</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678150</td>\n",
       "      <td>0.677335</td>\n",
       "      <td>0.733371</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>7.659916e-07</td>\n",
       "      <td>0.084304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.515798</td>\n",
       "      <td>0.594496</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.717065</td>\n",
       "      <td>0.756442</td>\n",
       "      <td>0.878233</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.432071e-06</td>\n",
       "      <td>0.194014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.587110</td>\n",
       "      <td>0.653739</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.782137</td>\n",
       "      <td>0.810931</td>\n",
       "      <td>0.970837</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.665199e-06</td>\n",
       "      <td>0.551714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature[C]   Humidity[%]     TVOC[ppb]     eCO2[ppm]        Raw H2  \\\n",
       "count    71672.000000  71672.000000  71672.000000  71672.000000  71672.000000   \n",
       "mean         0.476804      0.560188      0.044760      0.006029      0.721350   \n",
       "std          0.178753      0.158868      0.169140      0.038246      0.105182   \n",
       "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          0.416385      0.543423      0.001117      0.000000      0.678150   \n",
       "50%          0.515798      0.594496      0.004417      0.000000      0.717065   \n",
       "75%          0.587110      0.653739      0.019433      0.000483      0.782137   \n",
       "max          1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        Raw Ethanol  Pressure[hPa]         PM1.0         PM2.5         NC0.5  \\\n",
       "count  71672.000000   71672.000000  71672.000000  71672.000000  71672.000000   \n",
       "mean       0.744930       0.845509      0.010480      0.005908      0.012225   \n",
       "std        0.122311       0.147471      0.077818      0.050823      0.086655   \n",
       "min        0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.677335       0.733371      0.000062      0.000020      0.000099   \n",
       "50%        0.756442       0.878233      0.000123      0.000040      0.000197   \n",
       "75%        0.810931       0.970837      0.000143      0.000047      0.000230   \n",
       "max        1.000000       1.000000      0.998917      1.000000      1.000000   \n",
       "\n",
       "              NC1.0         NC2.5           CNT  \n",
       "count  71672.000000  7.167200e+04  71672.000000  \n",
       "mean       0.005694  3.753135e-03      0.323073  \n",
       "std        0.049729  4.114791e-02      0.296541  \n",
       "min        0.000000  0.000000e+00      0.000000  \n",
       "25%        0.000018  7.659916e-07      0.084304  \n",
       "50%        0.000036  1.432071e-06      0.194014  \n",
       "75%        0.000042  1.665199e-06      0.551714  \n",
       "max        1.000000  1.000000e+00      1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the basic statistic for our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "      <td>12526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.586315</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>0.727134</td>\n",
       "      <td>0.863081</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.420469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.174468</td>\n",
       "      <td>0.137481</td>\n",
       "      <td>0.136697</td>\n",
       "      <td>0.030984</td>\n",
       "      <td>0.088136</td>\n",
       "      <td>0.101993</td>\n",
       "      <td>0.145482</td>\n",
       "      <td>0.065182</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>0.071659</td>\n",
       "      <td>0.042347</td>\n",
       "      <td>0.035425</td>\n",
       "      <td>0.303578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.406523</td>\n",
       "      <td>0.570897</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689633</td>\n",
       "      <td>0.675693</td>\n",
       "      <td>0.871129</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.145121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.514523</td>\n",
       "      <td>0.611542</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.686526</td>\n",
       "      <td>0.883783</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.373285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.578228</td>\n",
       "      <td>0.659789</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.778309</td>\n",
       "      <td>0.781224</td>\n",
       "      <td>0.950355</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.684622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695201</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.998523</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990353</td>\n",
       "      <td>0.985488</td>\n",
       "      <td>0.999920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature[C]   Humidity[%]     TVOC[ppb]     eCO2[ppm]        Raw H2  \\\n",
       "count    12526.000000  12526.000000  12526.000000  12526.000000  12526.000000   \n",
       "mean         0.464844      0.586315      0.034599      0.004559      0.724818   \n",
       "std          0.174468      0.137481      0.136697      0.030984      0.088136   \n",
       "min          0.000000      0.000465      0.000000      0.000000      0.000000   \n",
       "25%          0.406523      0.570897      0.002233      0.000000      0.689633   \n",
       "50%          0.514523      0.611542      0.016467      0.000000      0.719298   \n",
       "75%          0.578228      0.659789      0.019850      0.000638      0.778309   \n",
       "max          1.000000      1.000000      1.000000      0.695201      0.999362   \n",
       "\n",
       "        Raw Ethanol  Pressure[hPa]         PM1.0         PM2.5         NC0.5  \\\n",
       "count  12526.000000   12526.000000  12526.000000  12526.000000  12526.000000   \n",
       "mean       0.727134       0.863081      0.007336      0.004142      0.008545   \n",
       "std        0.101993       0.145482      0.065182      0.043231      0.071659   \n",
       "min        0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.675693       0.871129      0.000088      0.000029      0.000141   \n",
       "50%        0.686526       0.883783      0.000126      0.000041      0.000202   \n",
       "75%        0.781224       0.950355      0.000146      0.000048      0.000234   \n",
       "max        0.998523       0.999445      1.000000      0.990890      1.000000   \n",
       "\n",
       "              NC1.0         NC2.5           CNT  \n",
       "count  12526.000000  12526.000000  12526.000000  \n",
       "mean       0.003993      0.002637      0.420469  \n",
       "std        0.042347      0.035425      0.303578  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000026      0.000001      0.145121  \n",
       "50%        0.000037      0.000001      0.373285  \n",
       "75%        0.000043      0.000002      0.684622  \n",
       "max        0.990353      0.985488      0.999920  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the basic statistic for our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "wBpklRL-ys6k",
    "outputId": "327aeca5-2977-420e-bb00-5648771461f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "      <td>62630.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.970424</td>\n",
       "      <td>48.539499</td>\n",
       "      <td>1942.057528</td>\n",
       "      <td>670.021044</td>\n",
       "      <td>12942.453936</td>\n",
       "      <td>19754.257912</td>\n",
       "      <td>938.627649</td>\n",
       "      <td>100.594309</td>\n",
       "      <td>184.467770</td>\n",
       "      <td>491.463608</td>\n",
       "      <td>203.586487</td>\n",
       "      <td>80.049042</td>\n",
       "      <td>10511.386157</td>\n",
       "      <td>0.714626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.359576</td>\n",
       "      <td>8.865367</td>\n",
       "      <td>7811.589055</td>\n",
       "      <td>1905.885439</td>\n",
       "      <td>272.464305</td>\n",
       "      <td>609.513156</td>\n",
       "      <td>1.331344</td>\n",
       "      <td>922.524245</td>\n",
       "      <td>1976.305615</td>\n",
       "      <td>4265.661251</td>\n",
       "      <td>2214.738556</td>\n",
       "      <td>1083.383189</td>\n",
       "      <td>7597.870997</td>\n",
       "      <td>0.451596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-22.010000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>10668.000000</td>\n",
       "      <td>15317.000000</td>\n",
       "      <td>930.852000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.994250</td>\n",
       "      <td>47.530000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>12830.000000</td>\n",
       "      <td>19435.000000</td>\n",
       "      <td>938.700000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>8.820000</td>\n",
       "      <td>1.384000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>3625.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.130000</td>\n",
       "      <td>50.150000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>12924.000000</td>\n",
       "      <td>19501.000000</td>\n",
       "      <td>938.816000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>12.450000</td>\n",
       "      <td>1.943000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>9336.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.409500</td>\n",
       "      <td>53.240000</td>\n",
       "      <td>1189.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>13109.000000</td>\n",
       "      <td>20078.000000</td>\n",
       "      <td>939.418000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>2.249000</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>17164.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.930000</td>\n",
       "      <td>75.200000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>13803.000000</td>\n",
       "      <td>21410.000000</td>\n",
       "      <td>939.861000</td>\n",
       "      <td>14333.690000</td>\n",
       "      <td>45432.260000</td>\n",
       "      <td>61482.030000</td>\n",
       "      <td>51914.680000</td>\n",
       "      <td>30026.438000</td>\n",
       "      <td>24993.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature[C]   Humidity[%]     TVOC[ppb]     eCO2[ppm]        Raw H2  \\\n",
       "count    62630.000000  62630.000000  62630.000000  62630.000000  62630.000000   \n",
       "mean        15.970424     48.539499   1942.057528    670.021044  12942.453936   \n",
       "std         14.359576      8.865367   7811.589055   1905.885439    272.464305   \n",
       "min        -22.010000     10.740000      0.000000    400.000000  10668.000000   \n",
       "25%         10.994250     47.530000    130.000000    400.000000  12830.000000   \n",
       "50%         20.130000     50.150000    981.000000    400.000000  12924.000000   \n",
       "75%         25.409500     53.240000   1189.000000    438.000000  13109.000000   \n",
       "max         59.930000     75.200000  60000.000000  60000.000000  13803.000000   \n",
       "\n",
       "        Raw Ethanol  Pressure[hPa]         PM1.0         PM2.5         NC0.5  \\\n",
       "count  62630.000000   62630.000000  62630.000000  62630.000000  62630.000000   \n",
       "mean   19754.257912     938.627649    100.594309    184.467770    491.463608   \n",
       "std      609.513156       1.331344    922.524245   1976.305615   4265.661251   \n",
       "min    15317.000000     930.852000      0.000000      0.000000      0.000000   \n",
       "25%    19435.000000     938.700000      1.280000      1.340000      8.820000   \n",
       "50%    19501.000000     938.816000      1.810000      1.880000     12.450000   \n",
       "75%    20078.000000     939.418000      2.090000      2.180000     14.420000   \n",
       "max    21410.000000     939.861000  14333.690000  45432.260000  61482.030000   \n",
       "\n",
       "              NC1.0         NC2.5           CNT    Fire Alarm  \n",
       "count  62630.000000  62630.000000  62630.000000  62630.000000  \n",
       "mean     203.586487     80.049042  10511.386157      0.714626  \n",
       "std     2214.738556   1083.383189   7597.870997      0.451596  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        1.384000      0.033000   3625.250000      0.000000  \n",
       "50%        1.943000      0.044000   9336.000000      1.000000  \n",
       "75%        2.249000      0.051000  17164.750000      1.000000  \n",
       "max    51914.680000  30026.438000  24993.000000      1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fi-ExoYKxOH"
   },
   "source": [
    "**<h2> Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghTYH8dqNKpJ"
   },
   "source": [
    "<h3> Binomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_AHHmwrxmQMM"
   },
   "outputs": [],
   "source": [
    "logreg = SGDClassifier(loss='log', eta0=0.001, learning_rate='optimal', random_state=1, verbose=0)\n",
    "max_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6XgfNiqDu4HL"
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.indices = np.array([i for i in range(self.X.shape[0])])\n",
    "        np.random.seed(1)\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    def get_batch(self, mode='train'):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.shuffle()\n",
    "            \n",
    "        elif mode == 'test':\n",
    "            self.indices = np.array([i for i in range(self.X.shape[0])])\n",
    "\n",
    "        for i in range(0, len(self.indices), self.batch_size):\n",
    "            if i + self.batch_size <= len(self.indices):\n",
    "                indices = self.indices[i:i + self.batch_size]\n",
    "            else:\n",
    "                indices = self.indices[i:]\n",
    "\n",
    "            X_batch.append(self.X.iloc[indices])\n",
    "            y_batch.append(self.y.iloc[indices])\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DloWbNyu8do",
    "outputId": "8a4d16e5-c970-4e23-ad89-80dbb207da88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(X=X_train, y=y_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIRXQAmGmogw",
    "outputId": "b2ed7b9f-5610-4deb-8c13-5251fa0cc1e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 0.18251231400668882\n",
      "Epoch: 2 \tLoss: 0.14579636148569664\n",
      "Epoch: 3 \tLoss: 0.1449652801164937\n",
      "Epoch: 4 \tLoss: 0.14461415137499478\n",
      "Epoch: 5 \tLoss: 0.14440043884768766\n",
      "Epoch: 6 \tLoss: 0.14412213218356978\n",
      "Epoch: 7 \tLoss: 0.14413847919079972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "e = 0\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "labels = np.unique(y_train)\n",
    "\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    loss=0\n",
    "    \n",
    "    X_batch,y_batch = data_loader.get_batch()\n",
    "    \n",
    "    for X,y in zip(X_batch,y_batch):\n",
    "        logreg.partial_fit(X,y,classes=labels)\n",
    "        y_pred = logreg.predict_proba(X_train)\n",
    "        loss += log_loss(y_train,y_pred)\n",
    "        \n",
    "    print('Epoch:', e + 1, '\\tLoss:', (loss / len(X_batch)))\n",
    "    \n",
    "    if abs(previous_loss - loss)<0.1:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "aXb1vqIUm29T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "CyMBA1HgnAT7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11637 out of 12526\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(predictions == y_test)\n",
    "print(num_correct, 'out of', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "KaHdoVJsncI5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.90276225451062 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = num_correct / len(y_test) * 100\n",
    "print(accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hNRfbFV-niok",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      3605\n",
      "           1       0.99      0.91      0.95      8921\n",
      "\n",
      "    accuracy                           0.93     12526\n",
      "   macro avg       0.90      0.94      0.92     12526\n",
      "weighted avg       0.94      0.93      0.93     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od_zECQNNQ_R"
   },
   "source": [
    "<h3> Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating the model and training the model with our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's now generate predictions using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = gnb.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test if our model generated accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10177 out of 12526\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(predictions == y_test)\n",
    "print(num_correct, 'out of', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.24700622704773 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = num_correct / len(y_test) * 100\n",
    "print(accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the data above, overall the model's accuracy is fairly accurate with only an accuracy score of 81.75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets display a classification report to further evaluate the overall performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.41      0.55      3605\n",
      "           1       0.80      0.98      0.88      8921\n",
      "\n",
      "    accuracy                           0.81     12526\n",
      "   macro avg       0.84      0.69      0.72     12526\n",
      "weighted avg       0.82      0.81      0.79     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa2nrtFrNWRc"
   },
   "source": [
    "<h3> k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is suitable for this dataset because of how the dataset contains different numerical values. By using kNN, we will be using the euclidean distance or manhattan distance to get the nearest neighbors and predict data.\n",
    "\n",
    "Let's import the `KNeighborsClassifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be setting the hyperparameter k = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the `KNeighborsClassifier` object to `knn` and use `fit()` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = neighbors)\n",
    "knn = knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the training model using `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the accuracy of the model in the train set. As seen in the data below, 71667 out of 71672 are correct and the model's accuracy in the train set is 99.99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71668 out of 71672\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(y_train_knn == y_train)\n",
    "print(num_correct, 'out of', len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9944190199799 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = num_correct / len(y_train) * 100\n",
    "print(accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's now test the test model using `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function `classification_report()` to evaluate the performance of our model. According to the output, we have produced pretty good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3605\n",
      "           1       1.00      1.00      1.00      8921\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printClassificationReport = classification_report(y_test, y_test_knn)\n",
    "print(printClassificationReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the accuracy of the model in the test set. As seen in the data below, 12524 out of 12526 are correct and the model's accuracy in the test set is 99.98%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12524 out of 12526\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(y_test_knn == y_test)\n",
    "print(num_correct, 'out of', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.98403321092128 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = num_correct / len(y_test) * 100\n",
    "print(accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare our Train Score and Test Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Train Score:  0.9999441901997991\n",
      "KNN Test Score:  0.9998403321092129\n"
     ]
    }
   ],
   "source": [
    "print('KNN Train Score: ', knn.score(X_train, y_train))\n",
    "print('KNN Test Score: ', knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation for kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of hyperparameter tuning, we will be doing cross-validation for kNN since results show we already have high accuracy. For cross-validation, we will be testing whether or not our k has the best results by using the k-fold cross-validation method.\n",
    "\n",
    "Let us first import the packages needed for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k_folds` will be set to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k_choices` will be an array of hyperparameter `k` that we will be testing in order to find the best one. We will also set the `scores` matrix temporarily to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_choices = [1, 3, 5, 7, 9, 11, 13, 15, 17, 20, 40, 50, 60, 80, 100]\n",
    "scores = np.zeros((len(k_choices), k_folds))\n",
    "ave_accuracy = [None] * len(k_choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at the `k-fold` per hyperparameter `k` in `k_choices` and see which is the best one by showing the scores per fold in each k and compute the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k is : 1\n",
      "Scores per fold :\n",
      "[1.         1.         0.99976247 0.99988124 1.         1.\n",
      " 0.99988124 0.99988124 0.99988122 1.        ]\n",
      "Average accuracy : 0.9999287396819602\n",
      "k is : 3\n",
      "Scores per fold :\n",
      "[1.         1.         0.99988124 0.99988124 1.         1.\n",
      " 0.99976247 0.99976247 0.99976244 1.        ]\n",
      "Average accuracy : 0.9999049853021627\n",
      "k is : 5\n",
      "Scores per fold :\n",
      "[1.         1.         0.99988124 0.99988124 1.         1.\n",
      " 0.99988124 0.99976247 0.99964366 1.        ]\n",
      "Average accuracy : 0.9999049838914862\n",
      "k is : 7\n",
      "Scores per fold :\n",
      "[1.         1.         0.99964371 0.99988124 1.         0.99976247\n",
      " 0.99988124 0.99976247 0.99976244 1.        ]\n",
      "Average accuracy : 0.999869355848481\n",
      "k is : 9\n",
      "Scores per fold :\n",
      "[1.         1.         0.99952494 0.99988124 1.         0.99988124\n",
      " 0.99988124 0.99976247 0.99976244 1.        ]\n",
      "Average accuracy : 0.999869355848481\n",
      "k is : 11\n",
      "Scores per fold :\n",
      "[1.         1.         0.99940618 0.99988124 0.99988124 0.99988124\n",
      " 1.         0.99976247 0.99976244 1.        ]\n",
      "Average accuracy : 0.9998574793639203\n",
      "k is : 13\n",
      "Scores per fold :\n",
      "[0.99988124 1.         0.99940618 0.99988124 0.99988124 0.99988124\n",
      " 1.         0.99976247 0.99976244 1.        ]\n",
      "Average accuracy : 0.9998456028793598\n",
      "k is : 15\n",
      "Scores per fold :\n",
      "[0.99988124 1.         0.99940618 0.99988124 0.99988124 0.99988124\n",
      " 1.         0.99976247 0.99976244 0.99988122]\n",
      "Average accuracy : 0.9998337249841228\n",
      "k is : 17\n",
      "Scores per fold :\n",
      "[0.99988124 1.         0.99940618 0.99988124 0.99988124 0.99988124\n",
      " 1.         0.99988124 0.99976244 0.99904977]\n",
      "Average accuracy : 0.9997624562020248\n",
      "k is : 20\n",
      "Scores per fold :\n",
      "[0.99988124 0.99988124 0.99916865 0.99976247 0.99976247 0.99976247\n",
      " 1.         0.99976247 0.99964366 0.99928733]\n",
      "Average accuracy : 0.9996911987053376\n",
      "k is : 40\n",
      "Scores per fold :\n",
      "[0.99976247 1.         0.99916865 0.99976247 0.99976247 0.99976247\n",
      " 1.         0.99964371 0.99952488 0.99916855]\n",
      "Average accuracy : 0.9996555664303031\n",
      "k is : 50\n",
      "Scores per fold :\n",
      "[0.99976247 0.99988124 0.99916865 0.99976247 0.99976247 0.99964371\n",
      " 1.         0.99964371 0.99952488 0.99916855]\n",
      "Average accuracy : 0.9996318134611821\n",
      "k is : 60\n",
      "Scores per fold :\n",
      "[0.99976247 0.99988124 0.99916865 0.99976247 0.99976247 0.99952494\n",
      " 1.         0.99964371 0.99940611 0.99916855]\n",
      "Average accuracy : 0.9996080590813845\n",
      "k is : 80\n",
      "Scores per fold :\n",
      "[0.99976247 0.99988124 0.99916865 0.99964371 0.99976247 0.99952494\n",
      " 1.         0.99952494 0.99940611 0.99904977]\n",
      "Average accuracy : 0.9995724282170263\n",
      "k is : 100\n",
      "Scores per fold :\n",
      "[0.99952494 0.99940618 0.99881235 0.99916865 0.99904988 0.99928741\n",
      " 0.99928741 0.99916865 0.99916855 0.99857465]\n",
      "Average accuracy : 0.9991448663087874\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "for i in range(len(k_choices)):\n",
    "    print(\"k is : \" + str(k_choices[i]))\n",
    "    model = KNeighborsClassifier(n_neighbors=k_choices[i])\n",
    "    scores[i] = cross_val_score(model.fit(X_train, y_train), X, y, cv=k_folds)\n",
    "    ave_accuracy[i] = np.sum(scores[i]) / len(scores[i])\n",
    "    print(\"Scores per fold :\\n\" + str(scores[i]))\n",
    "    print(\"Average accuracy : \" + str(ave_accuracy[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the output above, as the hyperparameter `k` increases the average accuracy becomes lower, however it is still super high and its change is very minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter graph shows the hyperparameter `k` in the x-axis and its accuracy per `k-fold` in the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scatter(scores):\n",
    "    for i in range(len(scores)):\n",
    "        x = [k_choices[i]] * 10\n",
    "        plt.scatter(x, scores[i])\n",
    "plot_scatter(scores)\n",
    "\n",
    "plt.xlabel('Hyperparameter k')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `np.mean` and `np.std` to get the average accuracy of the different hyperparameter k and show it in the graph as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy_mean = np.mean(scores,axis=1)\n",
    "avg_scores = average_accuracy_mean\n",
    "\n",
    "average_accuracy_std = np.std(scores, axis=1)\n",
    "stddev_scores = average_accuracy_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scatter(scores)\n",
    "\n",
    "plt.errorbar(k_choices, avg_scores, yerr=stddev_scores)\n",
    "\n",
    "plt.xlabel('Hyperparameter k')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using k-fold cross-validation, we were able to see that the hyperparameter `k` remains high even when `k = 100`. However, if we want to choose the hyperparameter k with the highest accuracy score, it will be around `k = 1` to `k = 20`. Since the average accuracy score is already high, we won't be changing the `n_neighbor` of the model. The cross-validation proved that we have the right value of hyperparameter `k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEXLv1mlK2cq"
   },
   "source": [
    "**<h2> Hyperparameter Tuning**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qa-sWBzD-LKK"
   },
   "source": [
    "<h3> Binomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"eta0\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"learning_rate\" : [\"constant\", \"optimal\"],\n",
    "}\n",
    "\n",
    "model = SGDClassifier(max_iter=1000)\n",
    "clf = GridSearchCV(model, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9724996747825279\n",
      "SGDClassifier(eta0=0.001, loss='squared_hinge')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = SGDClassifier(loss='log', eta0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 0.14410405072674945\n",
      "Epoch: 2 \tLoss: 0.14395892886148925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "e = 0\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "labels = np.unique(y_train)\n",
    "\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    loss=0\n",
    "    \n",
    "    X_batch,y_batch = data_loader.get_batch()\n",
    "    \n",
    "    for X,y in zip(X_batch,y_batch):\n",
    "        logreg.partial_fit(X,y,classes=labels)\n",
    "        y_pred = logreg.predict_proba(X_train)\n",
    "        loss += log_loss(y_train,y_pred)\n",
    "        \n",
    "    print('Epoch:', e + 1, '\\tLoss:', (loss / len(X_batch)))\n",
    "    \n",
    "    if abs(previous_loss - loss)<0.1:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = logreg.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11572 out of 12526\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(predictions == y_test)\n",
    "print(num_correct, 'out of', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.38384160945235 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = num_correct / len(y_test) * 100\n",
    "print(accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      3605\n",
      "           1       0.99      0.90      0.94      8921\n",
      "\n",
      "    accuracy                           0.92     12526\n",
      "   macro avg       0.90      0.94      0.91     12526\n",
      "weighted avg       0.94      0.92      0.93     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squared Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqhinge = SGDClassifier(loss='squared_hinge', eta0=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leigh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(eta0=0.0001, loss=&#x27;squared_hinge&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(eta0=0.0001, loss=&#x27;squared_hinge&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(eta0=0.0001, loss='squared_hinge')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqhinge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = sqhinge.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12216 out of 12526\n"
     ]
    }
   ],
   "source": [
    "num_correct = np.sum(predictions == y_test)\n",
    "print(num_correct, 'out of', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.52514769279898 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = num_correct / len(y_test) * 100\n",
    "print(accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3605\n",
      "           1       0.99      0.98      0.98      8921\n",
      "\n",
      "    accuracy                           0.98     12526\n",
      "   macro avg       0.97      0.97      0.97     12526\n",
      "weighted avg       0.98      0.98      0.98     12526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the model training, KNN does not need a complex hyperparameter tuning since it already has a high accuracy score without it and KNN usually produces high accuracy with little to no hyperparameter tuning.\n",
    "\n",
    "KNN also only has one hyperparameter which is k. K is the number of nearest neighbors that the model will be taken into account when making a prediciton.\n",
    "\n",
    "Instead of hyperparameter tuning we instead used cross-validation. By using cross-validation, we can easily tune the hyperparameter k, and we will be able to see how different k values affect how well the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with tuning the hyperparameters, we will be using the Repeated Stratified K-Fold cross validator method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "                                    n_repeats=3, \n",
    "                                    random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use `GridSearchCV` to find the optimal parameter for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=5, random_state=999),\n",
       "             estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=5, random_state=999),\n",
       "             estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=5, random_state=999),\n",
       "             estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=gnb, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy')\n",
    "\n",
    "Data_transformed = PowerTransformer().fit_transform(X_test)\n",
    "\n",
    "gs_NB.fit(Data_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0.0002310129700083158}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_NB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the optimal value for the `var_smoothing` variable is `0.0002310129700083158`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8808080354321951"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_NB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.06482516365959 %\n"
     ]
    }
   ],
   "source": [
    "predict_test = gs_NB.predict(Data_transformed)\n",
    "\n",
    "num_correct = np.sum(predict_test == y_test)\n",
    "\n",
    "accuracy_test = num_correct / len(y_test) * 100\n",
    "print(accuracy_test, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning the hyperparameters the model was able to produce an accuracy score of 88% which is an improvement from the initial score which was at 81%. So it can be determined that the hyperparameter tuning was able to improve our model's accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7CBq6vHK6nu"
   },
   "source": [
    "**<h2> Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Binomial Logistic Regression model initially got an accuracy score of `92%`, but after tuning its hyperparameters we were able to achieve a `97%` accuracy score. We used `GridSearchCV` to test different parameters and discover the best performing one. After running this the optimal parameters discovered were a initial learning rate at `0.0001` and the loss function set to `squared hinge`.\n",
    "\n",
    "The Gaussian Naive Bayes model initially only scored `81%`. `GridSearchCV` was also used to discover the most optimal parameter while also using the Repeated Stratified K-Fold cross validator. The most optimal parameter discovered was when the `var_smoothing` was set to `0.0002310129700083158` which produced an `88%` accuracy score which is lower than the previous model discussed.\n",
    "\n",
    "Based on the results we gathered the KNN model would be the best fit for this dataset as it had the highest accuracy score with a score of `99%` without needing to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfI6vGlaK9Yy"
   },
   "source": [
    "**<h2> Insights and Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU8N85hNLEOV"
   },
   "source": [
    "**<h2> References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brownlee, J. (2018). A Gentle Introduction to k-fold Cross-Validation - MachineLearningMastery.com. MachineLearningMastery.com. https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    "Allibhai, E. (2018). Building a k-Nearest-Neighbors (k-NN) Model with Scikit-learn. Medium; Towards Data Science. https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a\n",
    "\n",
    "Rose, N. (2017). *SGDClassifier.* Kaggle. https://www.kaggle.com/code/nsrose7224/sgdclassifier/notebook\n",
    "\n",
    "Vardhan, V. (2022). *Smoke Detection Cross Model Validation.* Kaggle. \n",
    "https://www.kaggle.com/code/vishnuvardhan97/smoke-detection-cross-model-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
